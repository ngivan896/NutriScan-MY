{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Quick Test Training - å¿«é€Ÿæµ‹è¯•è®­ç»ƒ\n",
        "\n",
        "ä½¿ç”¨3å¼ nasi_lemakå›¾åƒæµ‹è¯•è®­ç»ƒæµç¨‹\n",
        "\n",
        "**æ³¨æ„**: è¿™åªæ˜¯æµ‹è¯•æµç¨‹ï¼Œä¸ä¼šå¾—åˆ°å¥½çš„æ¨¡å‹ï¼\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ç¯å¢ƒæ£€æŸ¥\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "%pip install ultralytics pillow pyyaml -q\n",
        "\n",
        "import torch\n",
        "import ultralytics\n",
        "from pathlib import Path\n",
        "\n",
        "print(f\"âœ… Ultralytics: {ultralytics.__version__}\")\n",
        "print(f\"âœ… PyTorch: {torch.__version__}\")\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"âœ… Device: {device}\")\n",
        "if device == 'cuda':\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"   âš ï¸  ä½¿ç”¨CPUè®­ç»ƒä¼šå¾ˆæ…¢ï¼Œä½†å¯ä»¥éªŒè¯æµç¨‹\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. å‡†å¤‡æµ‹è¯•æ•°æ®é›†\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# åˆ›å»ºæµ‹è¯•æ•°æ®é›†ç›®å½•\n",
        "dataset_root = Path('test_dataset')\n",
        "dataset_root.mkdir(exist_ok=True)\n",
        "\n",
        "# åˆ›å»ºtrain/val/teståˆ†å‰²\n",
        "for split in ['train', 'valid', 'test']:\n",
        "    (dataset_root / split / 'images').mkdir(parents=True, exist_ok=True)\n",
        "    (dataset_root / split / 'labels').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ä»test_imageså¤åˆ¶å›¾åƒ\n",
        "test_images_dir = Path('../../test_images/nasi_lemak')\n",
        "images = list(test_images_dir.glob('*.jpg'))\n",
        "\n",
        "print(f\"æ‰¾åˆ° {len(images)} å¼ æµ‹è¯•å›¾åƒ\")\n",
        "\n",
        "# åˆ†é…ï¼š2å¼ è®­ç»ƒï¼Œ1å¼ éªŒè¯\n",
        "if len(images) >= 3:\n",
        "    train_images = images[:2]\n",
        "    val_images = images[2:3]\n",
        "    \n",
        "    for img in train_images:\n",
        "        shutil.copy(img, dataset_root / 'train' / 'images' / img.name)\n",
        "    \n",
        "    for img in val_images:\n",
        "        shutil.copy(img, dataset_root / 'valid' / 'images' / img.name)\n",
        "        shutil.copy(img, dataset_root / 'test' / 'images' / img.name)\n",
        "    \n",
        "    print(f\"âœ… è®­ç»ƒé›†: {len(train_images)} å¼ \")\n",
        "    print(f\"âœ… éªŒè¯é›†: {len(val_images)} å¼ \")\n",
        "else:\n",
        "    print(\"âŒ å›¾åƒä¸è¶³ï¼\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. åˆ›å»ºè™šæ‹Ÿæ ‡æ³¨\n",
        "\n",
        "ä¸ºæ¯å¼ å›¾åƒåˆ›å»ºç®€å•æ ‡æ³¨ï¼ˆè¦†ç›–æ•´å¼ å›¾ï¼‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def create_dummy_label(image_path, label_path, class_id=0):\n",
        "    \"\"\"åˆ›å»ºè¦†ç›–æ•´å¼ å›¾çš„è™šæ‹Ÿæ ‡æ³¨\"\"\"\n",
        "    img = Image.open(image_path)\n",
        "    width, height = img.size\n",
        "    \n",
        "    # YOLOæ ¼å¼: class_id x_center y_center width height\n",
        "    label_content = f\"{class_id} 0.5 0.5 0.9 0.9\\n\"\n",
        "    \n",
        "    with open(label_path, 'w') as f:\n",
        "        f.write(label_content)\n",
        "\n",
        "# ä¸ºæ‰€æœ‰å›¾åƒåˆ›å»ºæ ‡æ³¨\n",
        "for split in ['train', 'valid', 'test']:\n",
        "    images_dir = dataset_root / split / 'images'\n",
        "    labels_dir = dataset_root / split / 'labels'\n",
        "    \n",
        "    for img_path in images_dir.glob('*.jpg'):\n",
        "        label_path = labels_dir / f\"{img_path.stem}.txt\"\n",
        "        create_dummy_label(img_path, label_path, class_id=0)\n",
        "    \n",
        "    label_count = len(list(labels_dir.glob('*.txt')))\n",
        "    print(f\"âœ… {split}: åˆ›å»ºäº† {label_count} ä¸ªæ ‡æ³¨\")\n",
        "\n",
        "print(\"\\nâš ï¸  æ³¨æ„: è¿™äº›æ˜¯è™šæ‹Ÿæ ‡æ³¨ï¼Œä»…ç”¨äºæµ‹è¯•ï¼\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. åˆ›å»ºdata.yamlé…ç½®\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "# YOLOé…ç½®æ–‡ä»¶\n",
        "data_config = {\n",
        "    'path': str(dataset_root.absolute()),\n",
        "    'train': 'train/images',\n",
        "    'val': 'valid/images',\n",
        "    'test': 'test/images',\n",
        "    'nc': 1,\n",
        "    'names': ['nasi_lemak']\n",
        "}\n",
        "\n",
        "data_yaml = dataset_root / 'data.yaml'\n",
        "with open(data_yaml, 'w') as f:\n",
        "    yaml.dump(data_config, f, default_flow_style=False)\n",
        "\n",
        "print(\"âœ… data.yaml å·²åˆ›å»º\")\n",
        "print(f\"\\né…ç½®:\")\n",
        "print(yaml.dump(data_config, default_flow_style=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. å¿«é€Ÿè®­ç»ƒæµ‹è¯•\n",
        "\n",
        "â±ï¸ é¢„è®¡æ—¶é—´: CPU 5-10åˆ†é’Ÿ, GPU 1-2åˆ†é’Ÿ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"ğŸš€ å¼€å§‹æµ‹è¯•è®­ç»ƒ...\")\n",
        "print()\n",
        "\n",
        "# åŠ è½½æœ€å°æ¨¡å‹\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# å¿«é€Ÿè®­ç»ƒï¼ˆä»…æµ‹è¯•ï¼‰\n",
        "try:\n",
        "    results = model.train(\n",
        "        data=str(data_yaml),\n",
        "        epochs=3,              # åªè®­ç»ƒ3è½®\n",
        "        imgsz=640,\n",
        "        batch=1,\n",
        "        device=device,\n",
        "        project='test_runs',\n",
        "        name='quick_test',\n",
        "        patience=0,\n",
        "        save=True,\n",
        "        plots=False,\n",
        "        verbose=True,\n",
        "        # ç¦ç”¨æ•°æ®å¢å¼º\n",
        "        hsv_h=0,\n",
        "        hsv_s=0,\n",
        "        hsv_v=0,\n",
        "        mosaic=0\n",
        "    )\n",
        "    \n",
        "    print(\"\\nâœ… è®­ç»ƒæµç¨‹æµ‹è¯•æˆåŠŸï¼\")\n",
        "    print(\"\\nâš ï¸  é‡è¦:\")\n",
        "    print(\"   - è¿™åªæ˜¯æµ‹è¯•ï¼Œæ¨¡å‹ä¸ä¼šæœ‰å®é™…èƒ½åŠ›\")\n",
        "    print(\"   - éœ€è¦1000+å¼ å›¾åƒæ‰èƒ½è®­ç»ƒå‡ºå¥½æ¨¡å‹\")\n",
        "    print(\"   - ç»§ç»­Week 2æ•°æ®æ”¶é›†ï¼\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ å‡ºé”™: {e}\")\n",
        "    print(\"\\nå¯èƒ½åŸå› :\")\n",
        "    print(\"   1. å†…å­˜ä¸è¶³\")\n",
        "    print(\"   2. å›¾åƒæ ¼å¼é—®é¢˜\")\n",
        "    print(\"   3. PyTorchå®‰è£…é—®é¢˜\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. æµ‹è¯•æ¨ç†\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹\n",
        "trained_model = YOLO('test_runs/quick_test/weights/best.pt')\n",
        "\n",
        "# æµ‹è¯•æ¨ç†\n",
        "test_img = list((dataset_root / 'test/images').glob('*.jpg'))[0]\n",
        "results = trained_model(test_img)\n",
        "\n",
        "print(\"âœ… æ¨ç†æµ‹è¯•æˆåŠŸï¼\")\n",
        "print(f\"\\næ¨¡å‹è¾“å‡º: {results[0].boxes}\")\n",
        "print(\"\\nï¼ˆæ£€æµ‹å¯èƒ½ä¸å‡†ç¡®ï¼Œè¿™æ˜¯æ­£å¸¸çš„ï¼‰\")\n",
        "\n",
        "# æ˜¾ç¤ºå›¾åƒ\n",
        "import matplotlib.pyplot as plt\n",
        "img = Image.open(test_img)\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.title('Test Image')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## æ€»ç»“\n",
        "\n",
        "### âœ… æµ‹è¯•æˆåŠŸè¯´æ˜\n",
        "- è®­ç»ƒç¯å¢ƒé…ç½®æ­£ç¡®\n",
        "- è®­ç»ƒæµç¨‹å¯ä»¥è¿è¡Œ\n",
        "- å¯ä»¥ç»§ç»­æ•°æ®æ”¶é›†\n",
        "\n",
        "### ğŸ“Š å¯¹æ¯”\n",
        "\n",
        "| é¡¹ç›® | æµ‹è¯• | çœŸå®è®­ç»ƒ |\n",
        "|------|------|---------|\n",
        "| å›¾åƒ | 3å¼  | 1000+å¼  |\n",
        "| ç±»åˆ« | 1ç±» | 20ç±» |\n",
        "| Epochs | 3 | 100 |\n",
        "| æ—¶é—´ | 5-10åˆ†é’Ÿ | 2-4å°æ—¶ |\n",
        "| mAP50 | ~5% | >80% |\n",
        "\n",
        "### ğŸš€ ä¸‹ä¸€æ­¥\n",
        "1. ç»§ç»­Week 2æ•°æ®æ”¶é›†\n",
        "2. æ”¶é›†1000+å¼ å›¾åƒ\n",
        "3. ä¸Šä¼ Roboflowæ ‡æ³¨\n",
        "4. Week 3æ­£å¼è®­ç»ƒ\n",
        "\n",
        "---\n",
        "\n",
        "**ç°åœ¨å»æ”¶é›†æ•°æ®å§ï¼** ğŸ¯\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
