#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨¡å‹æ•°æ®åˆ†æè„šæœ¬
ç”¨äºæŸ¥çœ‹è®­ç»ƒåçš„æ¨¡å‹æ€§èƒ½å’Œæ•°æ®
"""

import os
import pandas as pd
import yaml
from ultralytics import YOLO
import torch

def analyze_training_results():
    """åˆ†æè®­ç»ƒç»“æœ"""
    print("=" * 60)
    print("ğŸ” æ¨¡å‹æ•°æ®åˆ†ææŠ¥å‘Š")
    print("=" * 60)
    
    # æ£€æŸ¥ç»“æœæ–‡ä»¶
    results_file = "test_runs/quick_test/results.csv"
    if os.path.exists(results_file):
        print("\nğŸ“Š è®­ç»ƒæ€§èƒ½æ•°æ®:")
        print("-" * 40)
        
        # è¯»å–CSVæ•°æ®
        df = pd.read_csv(results_file)
        
        # æ˜¾ç¤ºæœ€åä¸€è½®çš„æ•°æ®
        last_epoch = df.iloc[-1]
        print(f"æœ€ç»ˆè½®æ¬¡: {int(last_epoch['epoch'])}")
        print(f"è®­ç»ƒæ—¶é—´: {last_epoch['time']:.2f}ç§’")
        print(f"è®­ç»ƒæŸå¤± (Box): {last_epoch['train/box_loss']:.4f}")
        print(f"è®­ç»ƒæŸå¤± (åˆ†ç±»): {last_epoch['train/cls_loss']:.4f}")
        print(f"è®­ç»ƒæŸå¤± (DFL): {last_epoch['train/dfl_loss']:.4f}")
        print(f"éªŒè¯æŸå¤± (Box): {last_epoch['val/box_loss']:.4f}")
        print(f"éªŒè¯æŸå¤± (åˆ†ç±»): {last_epoch['val/cls_loss']:.4f}")
        print(f"éªŒè¯æŸå¤± (DFL): {last_epoch['val/dfl_loss']:.4f}")
        
        print("\nğŸ“ˆ æ€§èƒ½æŒ‡æ ‡:")
        print("-" * 40)
        print(f"ç²¾ç¡®åº¦ (Precision): {last_epoch['metrics/precision(B)']:.4f}")
        print(f"å¬å›ç‡ (Recall): {last_epoch['metrics/recall(B)']:.4f}")
        print(f"mAP@0.5: {last_epoch['metrics/mAP50(B)']:.4f}")
        print(f"mAP@0.5:0.95: {last_epoch['metrics/mAP50-95(B)']:.4f}")
        
        # æ˜¾ç¤ºæ‰€æœ‰è½®æ¬¡çš„æ•°æ®
        print("\nğŸ“‹ å®Œæ•´è®­ç»ƒå†å²:")
        print("-" * 40)
        print(df.to_string(index=False))
        
    else:
        print("âŒ æ‰¾ä¸åˆ°ç»“æœæ–‡ä»¶")

def analyze_model_weights():
    """åˆ†ææ¨¡å‹æƒé‡"""
    print("\n" + "=" * 60)
    print("ğŸ‹ï¸ æ¨¡å‹æƒé‡åˆ†æ")
    print("=" * 60)
    
    weights_dir = "test_runs/quick_test/weights/"
    
    if os.path.exists(weights_dir):
        best_model = os.path.join(weights_dir, "best.pt")
        last_model = os.path.join(weights_dir, "last.pt")
        
        print(f"\nğŸ“ æ¨¡å‹æ–‡ä»¶:")
        print(f"æœ€ä½³æ¨¡å‹: {best_model}")
        print(f"æœ€ç»ˆæ¨¡å‹: {last_model}")
        
        # åŠ è½½æ¨¡å‹ä¿¡æ¯
        try:
            model = YOLO(best_model)
            print(f"\nâœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
            print(f"æ¨¡å‹ç±»å‹: {type(model.model).__name__}")
            print(f"è®¾å¤‡: {model.device}")
            
            # è·å–æ¨¡å‹ä¿¡æ¯
            model_info = model.model
            total_params = sum(p.numel() for p in model_info.parameters())
            trainable_params = sum(p.numel() for p in model_info.parameters() if p.requires_grad)
            
            print(f"\nğŸ”¢ æ¨¡å‹å‚æ•°:")
            print(f"æ€»å‚æ•°æ•°é‡: {total_params:,}")
            print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
            print(f"æ¨¡å‹å¤§å°: {os.path.getsize(best_model) / (1024*1024):.2f} MB")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    else:
        print("âŒ æ‰¾ä¸åˆ°æƒé‡æ–‡ä»¶")

def analyze_dataset():
    """åˆ†ææ•°æ®é›†"""
    print("\n" + "=" * 60)
    print("ğŸ“‚ æ•°æ®é›†åˆ†æ")
    print("=" * 60)
    
    # æ£€æŸ¥æ•°æ®é›†é…ç½®
    data_yaml = "test_dataset/data.yaml"
    if os.path.exists(data_yaml):
        with open(data_yaml, 'r', encoding='utf-8') as f:
            data_config = yaml.safe_load(f)
        
        print(f"\nğŸ“‹ æ•°æ®é›†é…ç½®:")
        print(f"ç±»åˆ«æ•°é‡: {data_config['nc']}")
        print(f"ç±»åˆ«åç§°: {data_config['names']}")
        
        # ç»Ÿè®¡å›¾åƒæ•°é‡
        train_images = len([f for f in os.listdir("test_dataset/train/images") if f.endswith(('.jpg', '.png', '.jpeg'))])
        val_images = len([f for f in os.listdir("test_dataset/valid/images") if f.endswith(('.jpg', '.png', '.jpeg'))])
        test_images = len([f for f in os.listdir("test_dataset/test/images") if f.endswith(('.jpg', '.png', '.jpeg'))])
        
        print(f"\nğŸ“Š å›¾åƒç»Ÿè®¡:")
        print(f"è®­ç»ƒé›†: {train_images} å¼ ")
        print(f"éªŒè¯é›†: {val_images} å¼ ")
        print(f"æµ‹è¯•é›†: {test_images} å¼ ")
        print(f"æ€»è®¡: {train_images + val_images + test_images} å¼ ")
        
        # ç»Ÿè®¡æ ‡ç­¾æ•°é‡
        train_labels = len([f for f in os.listdir("test_dataset/train/labels") if f.endswith('.txt')])
        val_labels = len([f for f in os.listdir("test_dataset/valid/labels") if f.endswith('.txt')])
        test_labels = len([f for f in os.listdir("test_dataset/test/labels") if f.endswith('.txt')])
        
        print(f"\nğŸ·ï¸ æ ‡ç­¾ç»Ÿè®¡:")
        print(f"è®­ç»ƒæ ‡ç­¾: {train_labels} ä¸ª")
        print(f"éªŒè¯æ ‡ç­¾: {val_labels} ä¸ª")
        print(f"æµ‹è¯•æ ‡ç­¾: {test_labels} ä¸ª")
        print(f"æ€»è®¡: {train_labels + val_labels + test_labels} ä¸ª")
        
    else:
        print("âŒ æ‰¾ä¸åˆ°æ•°æ®é›†é…ç½®æ–‡ä»¶")

def test_model_inference():
    """æµ‹è¯•æ¨¡å‹æ¨ç†"""
    print("\n" + "=" * 60)
    print("ğŸ§ª æ¨¡å‹æ¨ç†æµ‹è¯•")
    print("=" * 60)
    
    best_model_path = "test_runs/quick_test/weights/best.pt"
    
    if os.path.exists(best_model_path):
        try:
            model = YOLO(best_model_path)
            
            # æµ‹è¯•ä¸€å¼ å›¾åƒ
            test_image = "test_dataset/test/images/pexels-suhairytriyadhi-11912788.jpg"
            if os.path.exists(test_image):
                print(f"\nğŸ–¼ï¸ æµ‹è¯•å›¾åƒ: {test_image}")
                
                results = model(test_image, conf=0.1, verbose=False)
                
                print(f"æ£€æµ‹ç»“æœ:")
                for r in results:
                    boxes = r.boxes
                    if boxes is not None:
                        print(f"æ£€æµ‹åˆ° {len(boxes)} ä¸ªå¯¹è±¡")
                        for i, box in enumerate(boxes):
                            cls_id = int(box.cls[0])
                            conf = float(box.conf[0])
                            print(f"  å¯¹è±¡ {i+1}: ç±»åˆ«={cls_id}, ç½®ä¿¡åº¦={conf:.3f}")
                    else:
                        print("æœªæ£€æµ‹åˆ°ä»»ä½•å¯¹è±¡")
            else:
                print("âŒ æ‰¾ä¸åˆ°æµ‹è¯•å›¾åƒ")
                
        except Exception as e:
            print(f"âŒ æ¨ç†æµ‹è¯•å¤±è´¥: {e}")
    else:
        print("âŒ æ‰¾ä¸åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹åˆ†ææ¨¡å‹æ•°æ®...")
    
    # æ£€æŸ¥ç¯å¢ƒ
    print(f"Pythonç‰ˆæœ¬: {torch.__version__}")
    print(f"è®¾å¤‡: {'CUDA' if torch.cuda.is_available() else 'CPU'}")
    
    # åˆ†æå„ä¸ªéƒ¨åˆ†
    analyze_training_results()
    analyze_model_weights()
    analyze_dataset()
    test_model_inference()
    
    print("\n" + "=" * 60)
    print("âœ… åˆ†æå®Œæˆ!")
    print("=" * 60)

if __name__ == "__main__":
    main()
